{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "686b30b3-2007-4e73-9e71-c6281f227a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ocb/HardDrive_4TB/EGM/PHX/PhotoFITT/photofitt/\")\n",
    "from utils.normalisation import normalise_phc_timelapse\n",
    "import tifffile\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import czifile as zis\n",
    "import shutil\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "def normalise_data(Source_QC_folder, Target_QC_folder, Normalisation_QC_source, Normalisation_QC_target, Im_path):\n",
    "    if Normalisation_QC_source == \"Contrast stretching\":\n",
    "\n",
    "        for filename in os.listdir(Source_QC_folder):\n",
    "\n",
    "            img = io.imread(os.path.join(Source_QC_folder,filename)).astype(np.float32)\n",
    "            short_name = os.path.splitext(filename)\n",
    "\n",
    "            p2, p99 = np.percentile(img, (1., 99.9))\n",
    "            img = exposure.rescale_intensity(img, in_range=(p2, p99))\n",
    "\n",
    "            img = 255 * img # Now scale by 255\n",
    "            img = img.astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(Im_path, \"A\", \"test\", f\"{short_name[0]}.png\"), img)\n",
    "\n",
    "    if Normalisation_QC_target == \"Contrast stretching\":\n",
    "        for filename in os.listdir(Target_QC_folder):\n",
    "\n",
    "            img = io.imread(os.path.join(Target_QC_folder,filename)).astype(np.float32)\n",
    "            short_name = os.path.splitext(filename)\n",
    "\n",
    "            p2, p99 = np.percentile(img, (1., 99.9))\n",
    "            img = exposure.rescale_intensity(img, in_range=(p2, p99))\n",
    "\n",
    "            img = 255 * img # Now scale by 255\n",
    "            img = img.astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(Im_path, \"B\", \"test\", f\"{short_name[0]}.png\"), img)\n",
    "\n",
    "    if Normalisation_QC_source == \"Adaptive Equalization\":\n",
    "        for filename in os.listdir(Source_QC_folder):\n",
    "\n",
    "            img = io.imread(os.path.join(Source_QC_folder,filename))\n",
    "            short_name = os.path.splitext(filename)\n",
    "\n",
    "            img = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "\n",
    "            img = 255 * img # Now scale by 255\n",
    "            img = img.astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(Im_path, \"A\", \"test\", f\"{short_name[0]}.png\"), img)\n",
    "\n",
    "\n",
    "    if Normalisation_QC_target == \"Adaptive Equalization\":\n",
    "        for filename in os.listdir(Target_QC_folder):\n",
    "\n",
    "            img = io.imread(os.path.join(Target_QC_folder,filename))\n",
    "            short_name = os.path.splitext(filename)\n",
    "\n",
    "            img = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "\n",
    "            img = 255 * img # Now scale by 255\n",
    "            img = img.astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(Im_path, \"B\", \"test\", f\"{short_name[0]}.png\"), img)\n",
    "\n",
    "    if Normalisation_QC_source == \"None\":\n",
    "        for filename in os.listdir(Source_QC_folder):\n",
    "            img = io.imread(os.path.join(Source_QC_folder,filename))\n",
    "            short_name = os.path.splitext(filename)\n",
    "            cv2.imwrite(os.path.join(Im_path, \"A\", \"test\", f\"{short_name[0]}.png\"), img)\n",
    "            \n",
    "    if Normalisation_QC_target == \"None\":\n",
    "        for filename in os.listdir(Target_QC_folder):\n",
    "            img = io.imread(os.path.join(Target_QC_folder,filename))\n",
    "            short_name = os.path.splitext(filename)\n",
    "            cv2.imwrite(os.path.join(Im_path, \"B\", \"test\", f\"{short_name[0]}.png\"), img)\n",
    "\n",
    "def stack2im(path2stack, path2im, ph_normalisation=False):\n",
    "    f = zis.CziFile(path2stack)\n",
    "    stack = f.asarray()\n",
    "    stack = stack.squeeze()\n",
    "    file_name = os.path.basename(path2stack)\n",
    "    file_name = os.path.splitext(file_name)\n",
    "    print(f\"{file_name} file loaded in python\")\n",
    "    os.makedirs(path2im, exist_ok=True)\n",
    "    for t in range(len(stack)):\n",
    "        if ph_normalisation:\n",
    "            im = normalise_phc_timelapse(stack[t], keep_mean=False)\n",
    "        else:\n",
    "            im = stack[t]\n",
    "        cv2.imwrite(os.path.join(path2im, f\"{file_name[0]}_{t:04d}.png\"), im)\n",
    "    #Find image XY dimension\n",
    "    Image_Y = im.shape[0]\n",
    "    Image_X = im.shape[1]\n",
    "    return min(Image_Y, Image_X)\n",
    "    \n",
    "\n",
    "\n",
    "def prepare_im_sequence(path2im, working_dir, pix2pix_code_dir, normalisation=\"Contrast stretching\"):\n",
    "    \n",
    "    # Here we need to move the data to be analysed so that pix2pix can find them\n",
    "    Saving_path_prediction= working_dir\n",
    "    \n",
    "    if os.path.exists(Saving_path_prediction):\n",
    "        shutil.rmtree(Saving_path_prediction)\n",
    "    os.makedirs(Saving_path_prediction, exist_ok=True)\n",
    "    \n",
    "    imageA_folder = os.path.join(Saving_path_prediction, \"A\")\n",
    "    os.makedirs(imageA_folder, exist_ok=True)\n",
    "    \n",
    "    imageB_folder = os.path.join(Saving_path_prediction, \"B\")\n",
    "    os.makedirs(imageB_folder, exist_ok=True)\n",
    "    \n",
    "    imageAB_folder = os.path.join(Saving_path_prediction, \"AB\")\n",
    "    os.makedirs(imageAB_folder, exist_ok=True)\n",
    "    \n",
    "    testAB_Folder = os.path.join(imageAB_folder, \"test\")\n",
    "    os.makedirs(testAB_Folder, exist_ok=True)\n",
    "    \n",
    "    testA_Folder = os.path.join(imageA_folder, \"test\")\n",
    "    os.makedirs(testA_Folder, exist_ok=True)\n",
    "    \n",
    "    testB_Folder = os.path.join(imageB_folder, \"test\")\n",
    "    os.makedirs(testB_Folder, exist_ok=True)\n",
    "    \n",
    "    # Normalise the image sequence with the pix2pix normalisation\n",
    "    print(path2im)\n",
    "    print(Saving_path_prediction)\n",
    "    normalise_data(path2im, path2im, normalisation, normalisation, Saving_path_prediction)\n",
    "\n",
    "    # Process normalised data for pix2pix to process it\n",
    "    os.chdir(pix2pix_code_dir)\n",
    "    !python3 pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A \"$imageA_folder\" --fold_B \"$imageB_folder\" --fold_AB \"$imageAB_folder\"\n",
    "    print(\"Images ready to be processed\")\n",
    "    print(f'AB folder placed in {imageAB_folder}')\n",
    "    \n",
    "    return imageAB_folder\n",
    "    \n",
    "def process_im_sequence(pix2pix_code_dir, imageAB_folder, Prediction_model_name, Prediction_model_path, Result_folder, Nb_files_Data_folder, patch_size=1024, checkpoint=\"latest\", nc=1):\n",
    "    \n",
    "    if not patch_size % 256 == 0:\n",
    "      patch_size = ((int(patch_size / 256)) * 256)\n",
    "      print (\" Your image dimensions are not divisible by 256; therefore your images have now been resized to:\",patch_size)\n",
    "    \n",
    "    if patch_size < 256:\n",
    "      patch_size = 256\n",
    "\n",
    "    \n",
    "    os.chdir(pix2pix_code_dir)\n",
    "    !python3 pytorch-CycleGAN-and-pix2pix/test.py --dataroot \"$imageAB_folder\" --name \"$Prediction_model_name\" --model pix2pix --no_dropout --preprocess scale_width --load_size $patch_size --crop_size $patch_size --results_dir \"$Result_folder\" --checkpoints_dir \"$Prediction_model_path\" --num_test $Nb_files_Data_folder --epoch $checkpoint --input_nc \"$nc\" --output_nc \"$nc\" --dataset_mode \"aligned\"\n",
    "    print(\"Images processed already\")\n",
    "\n",
    "\n",
    "def process_pix2pix(path2data, pix2pix_model_path, Result_folder, pix2pix_code_dir, working_dir, checkpoint=\"latest\", normalisation=\"Contrast stretching\", nc=1):\n",
    "    folders = os.listdir(path2data)\n",
    "    folders.sort\n",
    "    print(folders)\n",
    "    os.makedirs(Result_folder, exist_ok=True)\n",
    "    path2imsequence = os.path.join(working_dir, \"image_sequence\")\n",
    "    Prediction_model_name = os.path.basename(pix2pix_model_path)\n",
    "    Prediction_model_path = os.path.dirname(pix2pix_model_path)\n",
    "\n",
    "    if os.path.exists(path2imsequence):\n",
    "        shutil.rmtree(path2imsequence)\n",
    "    \n",
    "    for i in range(len(folders)):\n",
    "        f = folders[i]\n",
    "        if f[0] != '.':\n",
    "            if not f.__contains__('.'):\n",
    "\n",
    "                process_pix2pix(os.path.join(path2data, f), pix2pix_model_path, os.path.join(Result_folder, f), \n",
    "                                pix2pix_code_dir, working_dir, checkpoint=checkpoint, \n",
    "                                normalisation=normalisation, nc=nc)\n",
    "            elif f.__contains__('.czi'):\n",
    "                print(f)\n",
    "                # Convert the CZI stack into a normalised image sequence and save it in a general folder.\n",
    "                patch_size = stack2im(os.path.join(path2data, f), path2imsequence, ph_normalisation=True)\n",
    "                print(f'Images stored in {path2imsequence}')\n",
    "            \n",
    "                imageAB_folder = prepare_im_sequence(path2imsequence, os.path.join(working_dir, \"prepared_data\"), pix2pix_code_dir, normalisation=normalisation)\n",
    "                \n",
    "                Nb_files_Data_folder = len(os.listdir(os.path.join(imageAB_folder, \"test\")))+10\n",
    "                \n",
    "                process_im_sequence(pix2pix_code_dir, imageAB_folder, Prediction_model_name, Prediction_model_path,\n",
    "                                    Result_folder, Nb_files_Data_folder, patch_size=patch_size, checkpoint=checkpoint, nc=nc)\n",
    "\n",
    "                Checkpoint_name = \"test_\"+str(checkpoint)\n",
    "\n",
    "                \n",
    "                Prediction_results_folder = os.path.join(Result_folder, Prediction_model_name, Checkpoint_name, \"images\")\n",
    "                \n",
    "                Prediction_results_images = os.listdir(Prediction_results_folder)\n",
    "                \n",
    "                for f in Prediction_results_images:\n",
    "                  if (f.endswith(\"_real_B.png\")):\n",
    "                    os.remove(Prediction_results_folder+\"/\"+f)\n",
    "                \n",
    "                \n",
    "                os.makedirs(os.path.join(Prediction_results_folder + \"_fake_B\"),exist_ok=True)\n",
    "                os.makedirs(os.path.join(Prediction_results_folder + \"_real_A\"),exist_ok=True)\n",
    "                \n",
    "                for f in os.listdir(Prediction_results_folder):\n",
    "                    if f.endswith(\"fake_B.png\"):\n",
    "                        shutil.copy(os.path.join(Prediction_results_folder, f),\n",
    "                                    os.path.join(Prediction_results_folder + \"_fake_B\", f))\n",
    "                    elif f.endswith(\"real_A.png\"):\n",
    "                        shutil.copy(os.path.join(Prediction_results_folder, f),\n",
    "                                    os.path.join(Prediction_results_folder + \"_real_A\", f))\n",
    "                # Remove the images\n",
    "                shutil.rmtree(Prediction_results_folder)\n",
    "\n",
    "\n",
    "                if os.path.exists(path2imsequence):\n",
    "                    shutil.rmtree(path2imsequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5e30f-0486-4198-bef0-f082e7ba4512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20230627_unsync_630_day', '20230627_unsync_630_night', '20230628_unsync_UV_day', '20230628_unsync_UV_night', '20230629_unsync_475_night', '20230629_unsync_UV_day', '20230704_unsync_475_night', '20230705_unsync_630_day', '20230705_unsync_630_night', '20230706_unsync_UV_day', '20230706_unsync_UV_night']\n",
      "['._description_20230627_unsync_630_day.txt', 'description_20230627_unsync_630_day.txt', 'Individual']\n",
      "['CHO_unsync_630-live-01-Scene-01-P10-A01.czi', 'CHO_unsync_630-live-01-Scene-02-P7-A01.czi', 'CHO_unsync_630-live-01-Scene-03-P3-A01.czi', 'CHO_unsync_630-live-01-Scene-04-P6-A01.czi', 'CHO_unsync_630-live-01-Scene-05-P8-A01.czi', 'CHO_unsync_630-live-01-Scene-06-P9-A01.czi', 'CHO_unsync_630-live-01-Scene-07-P4-A01.czi', 'CHO_unsync_630-live-01-Scene-08-P5-A01.czi', 'CHO_unsync_630-live-01-Scene-09-P2-A01.czi', 'CHO_unsync_630-live-01-Scene-10-P1-A01.czi', 'CHO_unsync_630-live-01-Scene-11-P1-A02.czi', 'CHO_unsync_630-live-01-Scene-13-P3-A02.czi', 'CHO_unsync_630-live-01-Scene-14-P2-A02.czi', 'CHO_unsync_630-live-01-Scene-15-P8-A02.czi', 'CHO_unsync_630-live-01-Scene-16-P6-A02.czi', 'CHO_unsync_630-live-01-Scene-17-P7-A02.czi', 'CHO_unsync_630-live-01-Scene-18-P5-A02.czi', 'CHO_unsync_630-live-01-Scene-19-P9-A02.czi', 'CHO_unsync_630-live-01-Scene-20-P10-A02.czi', 'CHO_unsync_630-live-01-Scene-21-P2-A03.czi', 'CHO_unsync_630-live-01-Scene-22-P9-A03.czi', 'CHO_unsync_630-live-01-Scene-23-P7-A03.czi', 'CHO_unsync_630-live-01-Scene-25-P5-A03.czi', 'CHO_unsync_630-live-01-Scene-26-P8-A03.czi', 'CHO_unsync_630-live-01-Scene-27-P3-A03.czi', 'CHO_unsync_630-live-01-Scene-28-P10-A03.czi', 'CHO_unsync_630-live-01-Scene-29-P4-A03.czi', 'CHO_unsync_630-live-01-Scene-30-P1-A03.czi', 'CHO_unsync_630-live-01-Scene-31-P8-A04.czi', 'CHO_unsync_630-live-01-Scene-32-P3-A04.czi', 'CHO_unsync_630-live-01-Scene-33-P6-A04.czi', 'CHO_unsync_630-live-01-Scene-34-P2-A04.czi', 'CHO_unsync_630-live-01-Scene-35-P7-A04.czi', 'CHO_unsync_630-live-01-Scene-12-P4-A02.czi', 'CHO_unsync_630-live-01-Scene-24-P6-A03.czi', 'CHO_unsync_630-live-01-Scene-36-P10-A04.czi', 'CHO_unsync_630-live-01-Scene-48-P4-B04.czi', 'CHO_unsync_630-live-01-Scene-60-P7-B03.czi', 'CHO_unsync_630-live-01-Scene-37-P9-A04.czi', 'CHO_unsync_630-live-01-Scene-38-P1-A04.czi', 'CHO_unsync_630-live-01-Scene-39-P5-A04.czi', 'CHO_unsync_630-live-01-Scene-40-P4-A04.czi', 'CHO_unsync_630-live-01-Scene-41-P5-B04.czi', 'CHO_unsync_630-live-01-Scene-42-P8-B04.czi', 'CHO_unsync_630-live-01-Scene-43-P7-B04.czi', 'CHO_unsync_630-live-01-Scene-44-P1-B04.czi', 'CHO_unsync_630-live-01-Scene-45-P3-B04.czi', 'CHO_unsync_630-live-01-Scene-46-P6-B04.czi', 'CHO_unsync_630-live-01-Scene-47-P2-B04.czi', 'CHO_unsync_630-live-01-Scene-49-P10-B04.czi', 'CHO_unsync_630-live-01-Scene-50-P9-B04.czi', 'CHO_unsync_630-live-01-Scene-51-P8-B03.czi', 'CHO_unsync_630-live-01-Scene-52-P3-B03.czi', 'CHO_unsync_630-live-01-Scene-53-P9-B03.czi', 'CHO_unsync_630-live-01-Scene-54-P6-B03.czi', 'CHO_unsync_630-live-01-Scene-55-P1-B03.czi', 'CHO_unsync_630-live-01-Scene-56-P5-B03.czi', 'CHO_unsync_630-live-01-Scene-57-P10-B03.czi', 'CHO_unsync_630-live-01-Scene-58-P4-B03.czi', 'CHO_unsync_630-live-01-Scene-59-P2-B03.czi', 'CHO_unsync_630-live-01-Scene-61-P2-B02.czi', 'CHO_unsync_630-live-01-Scene-62-P10-B02.czi', 'CHO_unsync_630-live-01-Scene-63-P9-B02.czi', 'CHO_unsync_630-live-01-Scene-64-P1-B02.czi', 'CHO_unsync_630-live-01-Scene-65-P6-B02.czi', 'CHO_unsync_630-live-01-Scene-66-P5-B02.czi', 'CHO_unsync_630-live-01-Scene-67-P8-B02.czi', 'CHO_unsync_630-live-01-Scene-68-P7-B02.czi', 'CHO_unsync_630-live-01-Scene-69-P4-B02.czi', 'CHO_unsync_630-live-01-Scene-70-P3-B02.czi', 'CHO_unsync_630-live-01-Scene-71-P3-B01.czi', 'CHO_unsync_630-live-01-Scene-72-P8-B01.czi', 'CHO_unsync_630-live-01-Scene-73-P2-B01.czi', 'CHO_unsync_630-live-01-Scene-74-P7-B01.czi', 'CHO_unsync_630-live-01-Scene-75-P4-B01.czi', 'CHO_unsync_630-live-01-Scene-76-P1-B01.czi', 'CHO_unsync_630-live-01-Scene-77-P9-B01.czi', 'CHO_unsync_630-live-01-Scene-78-P5-B01.czi', 'CHO_unsync_630-live-01-Scene-79-P6-B01.czi', 'CHO_unsync_630-live-01-Scene-80-P10-B01.czi']\n",
      "CHO_unsync_630-live-01-Scene-01-P10-A01.czi\n",
      "('CHO_unsync_630-live-01-Scene-01-P10-A01', '.czi') file loaded in python\n",
      "Images stored in /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/image_sequence\n",
      "/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/image_sequence\n",
      "/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data\n",
      "[fold_A] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/A\n",
      "[fold_B] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/B\n",
      "[fold_AB] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  False\n",
      "split = test, use 121/121 images\n",
      "split = test, number of images = 121\n",
      "Images ready to be processed\n",
      "AB folder placed in /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\n",
      " Your image dimensions are not divisible by 256; therefore your images have now been resized to: 1024\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS\t[default: ./checkpoints]\n",
      "                crop_size: 1024                          \t[default: 256]\n",
      "                 dataroot: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 1024                          \t[default: 256]\n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024\t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 131                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: scale_width                   \t[default: resize_and_crop]\n",
      "              results_dir: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/RESULTS/PHX_DATA/20230627_unsync_630_day/Individual\t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.408 M\n",
      "-----------------------------------------------\n",
      "creating web directory /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/RESULTS/PHX_DATA/20230627_unsync_630_day/Individual/pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024/test_latest\n",
      "processing (0000)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0000.png']\n",
      "processing (0005)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0005.png']\n",
      "processing (0010)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0010.png']\n",
      "processing (0015)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0015.png']\n",
      "processing (0020)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0020.png']\n",
      "processing (0025)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0025.png']\n",
      "processing (0030)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0030.png']\n",
      "processing (0035)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0035.png']\n",
      "processing (0040)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0040.png']\n",
      "processing (0045)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0045.png']\n",
      "processing (0050)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0050.png']\n",
      "processing (0055)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0055.png']\n",
      "processing (0060)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0060.png']\n",
      "processing (0065)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0065.png']\n",
      "processing (0070)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0070.png']\n",
      "processing (0075)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0075.png']\n",
      "processing (0080)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0080.png']\n",
      "processing (0085)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0085.png']\n",
      "processing (0090)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0090.png']\n",
      "processing (0095)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0095.png']\n",
      "processing (0100)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0100.png']\n",
      "processing (0105)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0105.png']\n",
      "processing (0110)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0110.png']\n",
      "processing (0115)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0115.png']\n",
      "processing (0120)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-01-P10-A01_0120.png']\n",
      "Images processed already\n",
      "CHO_unsync_630-live-01-Scene-02-P7-A01.czi\n",
      "('CHO_unsync_630-live-01-Scene-02-P7-A01', '.czi') file loaded in python\n",
      "Images stored in /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/image_sequence\n",
      "/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/image_sequence\n",
      "/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data\n",
      "[fold_A] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/A\n",
      "[fold_B] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/B\n",
      "[fold_AB] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  False\n",
      "split = test, use 121/121 images\n",
      "split = test, number of images = 121\n",
      "Images ready to be processed\n",
      "AB folder placed in /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\n",
      " Your image dimensions are not divisible by 256; therefore your images have now been resized to: 1024\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS\t[default: ./checkpoints]\n",
      "                crop_size: 1024                          \t[default: 256]\n",
      "                 dataroot: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 1024                          \t[default: 256]\n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024\t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 131                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: scale_width                   \t[default: resize_and_crop]\n",
      "              results_dir: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/RESULTS/PHX_DATA/20230627_unsync_630_day/Individual\t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.408 M\n",
      "-----------------------------------------------\n",
      "creating web directory /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/RESULTS/PHX_DATA/20230627_unsync_630_day/Individual/pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024/test_latest\n",
      "processing (0000)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0000.png']\n",
      "processing (0005)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0005.png']\n",
      "processing (0010)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0010.png']\n",
      "processing (0015)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0015.png']\n",
      "processing (0020)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0020.png']\n",
      "processing (0025)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0025.png']\n",
      "processing (0030)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0030.png']\n",
      "processing (0035)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0035.png']\n",
      "processing (0040)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0040.png']\n",
      "processing (0045)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0045.png']\n",
      "processing (0050)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0050.png']\n",
      "processing (0055)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0055.png']\n",
      "processing (0060)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0060.png']\n",
      "processing (0065)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0065.png']\n",
      "processing (0070)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0070.png']\n",
      "processing (0075)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0075.png']\n",
      "processing (0080)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0080.png']\n",
      "processing (0085)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0085.png']\n",
      "processing (0090)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0090.png']\n",
      "processing (0095)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0095.png']\n",
      "processing (0100)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0100.png']\n",
      "processing (0105)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0105.png']\n",
      "processing (0110)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0110.png']\n",
      "processing (0115)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0115.png']\n",
      "processing (0120)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-02-P7-A01_0120.png']\n",
      "Images processed already\n",
      "CHO_unsync_630-live-01-Scene-03-P3-A01.czi\n",
      "('CHO_unsync_630-live-01-Scene-03-P3-A01', '.czi') file loaded in python\n",
      "Images stored in /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/image_sequence\n",
      "/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/image_sequence\n",
      "/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data\n",
      "[fold_A] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/A\n",
      "[fold_B] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/B\n",
      "[fold_AB] =  /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  False\n",
      "split = test, use 121/121 images\n",
      "split = test, number of images = 121\n",
      "Images ready to be processed\n",
      "AB folder placed in /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\n",
      " Your image dimensions are not divisible by 256; therefore your images have now been resized to: 1024\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS\t[default: ./checkpoints]\n",
      "                crop_size: 1024                          \t[default: 256]\n",
      "                 dataroot: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 1024                          \t[default: 256]\n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024\t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 131                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: scale_width                   \t[default: resize_and_crop]\n",
      "              results_dir: /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/RESULTS/PHX_DATA/20230627_unsync_630_day/Individual\t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.408 M\n",
      "-----------------------------------------------\n",
      "creating web directory /home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/RESULTS/PHX_DATA/20230627_unsync_630_day/Individual/pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024/test_latest\n",
      "processing (0000)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0000.png']\n",
      "processing (0005)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0005.png']\n",
      "processing (0010)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0010.png']\n",
      "processing (0015)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0015.png']\n",
      "processing (0020)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0020.png']\n",
      "processing (0025)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0025.png']\n",
      "processing (0030)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0030.png']\n",
      "processing (0035)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0035.png']\n",
      "processing (0040)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0040.png']\n",
      "processing (0045)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0045.png']\n",
      "processing (0050)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0050.png']\n",
      "processing (0055)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0055.png']\n",
      "processing (0060)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0060.png']\n",
      "processing (0065)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0065.png']\n",
      "processing (0070)-th image... ['/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/prepared_data/AB/test/CHO_unsync_630-live-01-Scene-03-P3-A01_0070.png']\n"
     ]
    }
   ],
   "source": [
    "#Here, we install libraries which are not already included in Colab.\n",
    "#!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "import os\n",
    "pix2pix_working_directory = \"/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/working_dir/\"\n",
    "pix2pix_code_dir = \"/home/ocb/HardDrive_4TB/EGM/PHX/PhotoFITT/notebooks/deep-learning/pix2pix/\"\n",
    "Result_folder = \"/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/RESULTS/PHX_DATA\"\n",
    "pix2pix_model_path = \"/home/ocb/HardDrive_4TB/EGM/MULTICHANNEL/PIX2PIX-MODELS/pix2pix_cho_selectedz_nuclei_ph_contrast_resized1024_18012024\"\n",
    "path2data = \"/home/ocb/HardDrive_4TB/EGM/PHX/DATA/RAW\"\n",
    "process_pix2pix(path2data, pix2pix_model_path, Result_folder, pix2pix_code_dir, pix2pix_working_directory, checkpoint=\"latest\", normalisation=\"Contrast stretching\", nc=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b377c7-bf3c-4a28-953a-85e233fe3e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
